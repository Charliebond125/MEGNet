{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1nzcMJqHjZ2A"
      },
      "source": [
        "<h2> SUBJECT 1 PREPROCESSING <h2/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OBj7gHHvj4Sl"
      },
      "outputs": [],
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "\n",
        "class meg_preprocessing_pipeline:\n",
        "\n",
        "    def __init__(self, raw):\n",
        "\n",
        "        self.raw = raw\n",
        "        self.eog_events = None\n",
        "        self.ecg_events = None\n",
        "        self.eog_projs = None\n",
        "        self.ecg_projs = None\n",
        "        self.epochs = None\n",
        "\n",
        "    def notch_filter(self):\n",
        "        self.raw.notch_filter(freqs=[50, 100, 150],\n",
        "                            picks='meg',\n",
        "                            method='spectrum_fit',\n",
        "                            filter_length='auto',\n",
        "                            fir_window='hamming',\n",
        "                            fir_design='firwin2',\n",
        "                            n_jobs=-1,\n",
        "                            verbose=True)\n",
        "        return self\n",
        "\n",
        "    def finding_bad_channels_maxwell(self):\n",
        "        \"\"\"\n",
        "        Using the inbuilt MNE operations to determine flat, or noisy channels as\n",
        "        automatic detection which can later be interpolated and addressed.\n",
        "        The automatic detection method specifically for MEG data should be\n",
        "        kind enough in determining averaged cut off points, and allocating the bad annotations.\n",
        "\n",
        "        It takes the empty list of bad channels, and updates them as it iterates over the channels.\n",
        "\n",
        "        Returns:\n",
        "            An updated list of bad channels based on noisy or flat/static channels.\n",
        "            ~ Flat or static channels indicate faulty sensor.\n",
        "            ~ Noisy channels indicate external noise, sensor issues etc.\n",
        "\n",
        "        Note:\n",
        "            It changes the data object in place, returning a new self.raw object\n",
        "            with updated and marked bad channels.\n",
        "\n",
        "        \"\"\"\n",
        "        from mne.preprocessing import find_bad_channels_maxwell\n",
        "        self.raw.info['bads'] = []\n",
        "\n",
        "        raw_check = self.raw.copy() # first uses a copy of the original raw data\n",
        "        auto_noisy_chs, auto_flat_chs, auto_scores = find_bad_channels_maxwell(raw_check, verbose=True, return_scores=True)\n",
        "        bads = self.raw.info['bads'] + auto_noisy_chs + auto_flat_chs # concatenates the empty list of bad channels, noisy channels, flat channels\n",
        "        self.raw.info['bads'] = bads # setting the bads parameter as the concetenated list\n",
        "\n",
        "        return self\n",
        "\n",
        "    def interpolate_bads(self):\n",
        "        \"\"\"\n",
        "        Interpolate bad channels in the MEG Data as marked by our bad channel detection method.\n",
        "\n",
        "        This function firstly creates a copy of the raw data,\n",
        "        then performs interpolation on the bad channels, based on good channels.\n",
        "\n",
        "        It then assigns the interpolated data back to the original raw object.\n",
        "\n",
        "        Returns:\n",
        "            self: The updated object with interpolated bad channels.\n",
        "\n",
        "        \"\"\"\n",
        "        # Create a copy of the raw data and perform interpolation\n",
        "        interpolated_raw = self.raw.copy().interpolate_bads(reset_bads=True)\n",
        "\n",
        "        # Assign interpolated data back to original raw\n",
        "        self.raw = interpolated_raw\n",
        "        self.raw.save(\"interpolated_bads_raw.fif\",overwrite=True)\n",
        "\n",
        "        return self, self.raw\n",
        "    \n",
        "    def estimate_continuous_head_pos(self):\n",
        "        self.raw.load_data()\n",
        "        chpi_freqs, ch_idx, chpi_codes = mne.chpi.get_chpi_info(info=self.raw.info)\n",
        "        chpi_amplitudes = mne.chpi.compute_chpi_amplitudes(self.raw)\n",
        "        chpi_locs = mne.chpi.compute_chpi_locs(self.raw.info, chpi_amplitudes)\n",
        "        self.head_pos = mne.chpi.compute_head_pos(self.raw.info, chpi_locs, gof_limit=0.5, verbose=True)\n",
        "        \n",
        "        \n",
        "        output_head_pos = 'head_pos.pos'\n",
        "        mne.chpi.write_head_pos(output_head_pos, self.head_pos)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def find_events(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Find and assigns annotations to events in the MEG data.\n",
        "\n",
        "        This function uses the mapping provided in the original dataset documentation\n",
        "        to assign event types based on the values detected\n",
        "        in the 'STI101' stimulus channel.\n",
        "\n",
        "        The events are then assigned annotations for later reference.\n",
        "\n",
        "        Returns:\n",
        "            self.events == an updated events object which can be used later.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Define the mapping of event values to event types in the dict.\n",
        "        mapping = {4: 'Motor/hand_imagery',\n",
        "                   8: 'Motor/feet_imagery',\n",
        "                   16: 'Mental/subtraction_imagery',\n",
        "                   32: 'Mental/word_imagery'}\n",
        "\n",
        "        # Find events based on the 'STI101' stimulus channel.\n",
        "        all_events = mne.find_events(self.raw, stim_channel='STI101',\n",
        "                                        initial_event=False,\n",
        "                                        verbose=True)\n",
        "        \n",
        "        # Filter events to include only those specified in the mapping dictionary\n",
        "\n",
        "        self.events = mne.pick_events(all_events, include=[4, 8, 16, 32])\n",
        "        print(f\"Events selected from data: {self.events[:,-1][:4]}\")\n",
        "\n",
        "        # Create annotations from the detected events, using the mapping dictionary created earlier.\n",
        "        annot_from_events = mne.annotations_from_events(events=self.events,\n",
        "                                                        event_desc=mapping,\n",
        "                                                        sfreq=self.raw.info['sfreq'],\n",
        "                                                        orig_time=self.raw.info['meas_date'])\n",
        "        \n",
        "        # Assign annotations to the raw data.\n",
        "        self.raw.set_annotations(annot_from_events)\n",
        "\n",
        "        # As checkpoint version control, saving events to file so we can access\n",
        "        # different parts of this pipeline if we need to that also requires\n",
        "        # the events file.\n",
        "        mne.write_events('events.txt', self.events, overwrite=True)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def bandpass_filter_butter(self):\n",
        "\n",
        "        sfreq=self.raw.info['sfreq']\n",
        "        nyquist_freq = sfreq / 2\n",
        "\n",
        "        l_freq= min(7, nyquist_freq)\n",
        "        h_freq= min(30, nyquist_freq)\n",
        "        order=4\n",
        "        ftype='butter'\n",
        "        sfreq=self.raw.info['sfreq']\n",
        "\n",
        "        iir_params = dict(order=order, ftype=ftype, output='sos')\n",
        "        raw_copy = self.raw.copy()\n",
        "        \n",
        "        filtered_data = mne.filter.filter_data(raw_copy.get_data(), sfreq=sfreq, l_freq=l_freq, h_freq=h_freq, method='iir',\n",
        "                                          phase='zero-double', iir_params=iir_params,\n",
        "                                          verbose=True)\n",
        "        \n",
        "        self.raw = mne.io.RawArray(filtered_data, info=self.raw.info)\n",
        "        self.raw.save(\"checkpoint_filter-raw.fif\", overwrite=True)\n",
        "        \n",
        "        return self, self.raw\n",
        "\n",
        "    def bandpass_butterworth_alpha_band(self):\n",
        "        \"\"\"\n",
        "        Appling a bandpass filter to the raw data.\n",
        "\n",
        "        This method utilizes a bandpass filter which is applied to the raw data using a bank specific for alpha frequency range {8,13}hz.\n",
        "\n",
        "        The chosen parameters include a 'IIR' design, with a 'hamming' window.\n",
        "        It utilizes the nyquist freqency ranges within both the lower and upper passband edge\n",
        "        to reduce the effect of artifact aliasing.\n",
        "\n",
        "        Returns:\n",
        "            self: The modified object with filtered data.\n",
        "\n",
        "        Note:\n",
        "            This method modifies the 'raw' attribute of the object in place,\n",
        "            computed across the two frequency ranges: {[8,13]} Hz.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        sfreq = self.raw.info['sfreq']\n",
        "        nyquist_freq = sfreq / 2\n",
        "\n",
        "        l_freq = min(8, nyquist_freq)  # Lower cutoff frequency\n",
        "        h_freq = min(13, nyquist_freq) # Upper cutoff frequency\n",
        "\n",
        "        filter_order = 4\n",
        "        ftype = 'butter'\n",
        "        sfreq = self.raw.info['sfreq']\n",
        "        iir_params = dict(order=filter_order, ftype=ftype)\n",
        "\n",
        "        self.raw = self.raw.filter(l_freq=l_freq, h_freq=h_freq,\n",
        "                                              method='iir', phase='zero',\n",
        "                                              iir_params=iir_params,\n",
        "                                              filter_length='auto',\n",
        "                                              verbose=True)\n",
        "        \n",
        "        self.raw.save(\"checkpoint_filter-raw.fif\", overwrite=True)\n",
        "        return self\n",
        "\n",
        "\n",
        "    def nyquist_st_duration(self):\n",
        "        sfreq = self.raw.info['sfreq']\n",
        "        nyquist_freq = sfreq / 2 # 500hz to reduce effect of aliasing\n",
        "\n",
        "        st_duration = self.raw.times[-1] / nyquist_freq\n",
        "        return st_duration\n",
        "    \n",
        "    def apply_tsss_filter(self):\n",
        "        st_duration = self.nyquist_st_duration()\n",
        "        head_pos = mne.chpi.read_head_pos(r\"head_pos.pos\")\n",
        "        self.raw = mne.io.read_raw_fif(r\"interpolated_bads_raw.fif\", preload=True)\n",
        "        self.raw = mne.preprocessing.maxwell_filter(self.raw, coord_frame='head', head_pos=head_pos, st_duration=st_duration, verbose=True)\n",
        "        self.raw.save('tsss_checkpoint_raw.fif', overwrite=True)\n",
        "        return self\n",
        "\n",
        "    def create_eog_ecg_projs(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Create projs from the MEG data based on event information.\n",
        "\n",
        "        This function uses the provided event dictionary to define event types,\n",
        "        and the corresponding event codes.\n",
        "\n",
        "        EOG/blink and ECG Artifact removal are computed via SSP projections from the MNE Library.\n",
        "\n",
        "        Returns:\n",
        "            self: ECG/EOG removed object.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        self.raw = mne.io.read_raw_fif(r\"tsss_checkpoint_raw.fif\", preload=True)\n",
        "        self.events = mne.read_events(r\"events.txt\")\n",
        "\n",
        "        # Specifying the EOG and ECG channels\n",
        "        eog_channel = [\"EOG001\", \"EOG002\"]\n",
        "        ecg_channel = \"ECG003\"\n",
        "\n",
        "        # Defining rejection criteria and flat threshold\n",
        "        reject = dict(grad=4000e-13) # 4000 femtoteslas\n",
        "\n",
        "        # Compute ECG projections\n",
        "        ecg_projs, _ = mne.preprocessing.compute_proj_ecg(self.raw,\n",
        "                                                                ch_name=ecg_channel,\n",
        "                                                                n_grad=1,\n",
        "                                                                n_mag=1,\n",
        "                                                                no_proj=True)\n",
        "\n",
        "        # Compute EOG/Blink projections\n",
        "        eog_projs, _ = mne.preprocessing.compute_proj_eog(self.raw,\n",
        "                                                                ch_name=eog_channel,\n",
        "                                                                n_grad=1,\n",
        "                                                                n_mag=1,\n",
        "                                                                no_proj=True)\n",
        "\n",
        "        # Add projectors to raw object ready for epoch creations\n",
        "        self.raw.add_proj(ecg_projs)\n",
        "        self.raw.add_proj(eog_projs)\n",
        "\n",
        "        self.raw.save(\"tsss_eog_ecg_ssp_repaired_raw.fif\", overwrite=True)\n",
        "\n",
        "    def create_epochs(self):\n",
        "        self.raw = mne.io.read_raw_fif(r\"tsss_eog_ecg_ssp_repaired_raw.fif\")\n",
        "        # Event dictionary mapping event types to codes\n",
        "        event_dict = {\n",
        "            \"hand_imagery\": 4,\n",
        "            \"feet_imagery\": 8,\n",
        "            \"subtraction_imagery\": 16,\n",
        "            \"word_imagery\": 32,\n",
        "        }\n",
        "\n",
        "        # Create epochs from raw data using events and event dict.\n",
        "\n",
        "        \"\"\" \n",
        "        \n",
        "        Whether to reject based on annotations. \n",
        "        If True (default), epochs overlapping with segments\n",
        "        whose description begins with 'bad' are rejected. \n",
        "        If False, no rejection based on annotations is performed. \n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "        self.epochs = mne.Epochs(self.raw, events=self.events,\n",
        "                            event_id=event_dict,\n",
        "                            tmin=-0.1, tmax=4, # Specifying -0.1 seconds before event onset, 4 seconds after.\n",
        "                            preload=True,\n",
        "                            reject_by_annotation=True, # segments marked as bad\n",
        "                            baseline=None,\n",
        "                            verbose=True)\n",
        "\n",
        "\n",
        "        # Save epoched data to file.\n",
        "        self.epochs.save('epochs-epo.fif', overwrite=True)\n",
        "\n",
        "        return self\n",
        "\n",
        "    \n",
        "\n",
        "    def apply_pipeline(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Applies a series of preprocessing steps to the raw data based on the defined pipeline.\n",
        "\n",
        "        Steps:\n",
        "        1. Finding bad channels using Maxwell filtering.\n",
        "        2. Interpolating bad channels.\n",
        "        3. Applying multiple bandpass Butterworth filters.\n",
        "        4. Finding events in the data.\n",
        "        5. Creating epochs based on the events.\n",
        "\n",
        "        Returns:\n",
        "        -------\n",
        "        self: Instance of the class.\n",
        "            The modified instance of the class with the applied\n",
        "            preprocessing steps\n",
        "\n",
        "        \"\"\"\n",
        "        # Estimate CHP\n",
        "        #self.estimate_continuous_head_pos()\n",
        "\n",
        "        # Notch Filtering\n",
        "        self.notch_filter()\n",
        "\n",
        "        # find events\n",
        "        self.find_events()\n",
        "        \n",
        "        # Apply a bandpass butterworth filter\n",
        "        \n",
        "        self.bandpass_filter_butter()\n",
        "        \n",
        "        # Find bad channels using maxwell filtering\n",
        "        self.finding_bad_channels_maxwell()\n",
        "\n",
        "        # bad channel interpolation\n",
        "        self.interpolate_bads()\n",
        "        \n",
        "        # apply tsss sampling\n",
        "        self.apply_tsss_filter()\n",
        "\n",
        "        # Create projectors for blinks and heartbeats \n",
        "        self.create_eog_ecg_projs()\n",
        "\n",
        "        # Create epochs\n",
        "        self.create_epochs()\n",
        "\n",
        "        return self\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Opening raw data file D:\\charl\\Documents\\CE901_MEG_DATA_AND_CODE\\MEG_BIDS\\MEG_BIDS\\sub-1[head_movement_squid_jump_detected]\\ses-1\\meg\\sub-1_ses-1_task-bcimici_meg.fif...\n",
            "    Read a total of 13 projection items:\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "        generated with autossp-1.0.1 (1 x 306)  idle\n",
            "    Range : 28000 ... 2000999 =     28.000 ...  2000.999 secs\n",
            "Ready.\n",
            "Reading 0 ... 1972999  =      0.000 ...  1972.999 secs...\n",
            "Filtering raw data in 1 contiguous segment\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:   16.6s\n",
            "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:   42.4s\n",
            "[Parallel(n_jobs=-1)]: Done 150 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 306 out of 306 | elapsed:  2.6min finished\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    while True:\n",
        "        filename = input(\"Please specify file path: \").replace('\"', '').replace(\"'\", \"\")\n",
        "        #filename.replace('\"', '').replace(\"'\", \"\")\n",
        "\n",
        "        if os.path.isfile(filename):\n",
        "            # Assuming valid file path detected\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid file path specified. Please try again.\")\n",
        "            break\n",
        "\n",
        "    raw = mne.io.read_raw_fif(filename, preload=True)\n",
        "    instance = meg_preprocessing_pipeline(raw)\n",
        "    instance.apply_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7AIrMJeF7QA"
      },
      "outputs": [],
      "source": [
        "pipeline = meg_preprocessing_pipeline(sub_1_ses_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.create_epochs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg_yEDkgIaZH",
        "outputId": "2d69b3d1-403e-4181-98d0-9324e57e74e2"
      },
      "outputs": [],
      "source": [
        "pipeline.apply_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = mne.read_epochs(r\"D:\\charl\\Documents\\CE901_MEG_DATA_AND_CODE\\PROCESSING_PIPE\\epoched_sub_1_ses_1-epo.fif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_baseline_corrected = epochs.apply_baseline((-0.2, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_baseline_corrected.compute_psd(fmax=100).plot(picks=\"grad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sfreq = 250\n",
        "epochs_resampled = epochs_baseline_corrected.copy().resample(new_sfreq, npad=\"auto\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_resampled.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_resampled.compute_psd(fmax=50).plot(picks='grad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_resampled.plot(picks='grad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw = epochs_resampled\n",
        "\n",
        "# Get the coordinates of the fiducial points\n",
        "nasion = raw.info['dig'][0]['r']  # Nasion coordinate\n",
        "lpa = raw.info['dig'][1]['r']  # Left preauricular point coordinate\n",
        "rpa = raw.info['dig'][2]['r']  # Right preauricular point coordinate\n",
        "\n",
        "# Calculate the mid-point between the left and right preauricular points\n",
        "midpoint = (lpa + rpa)\n",
        "\n",
        "# Calculate the vector representing the direction from the ears forward\n",
        "ear_to_front_vector = nasion + midpoint\n",
        "\n",
        "# Calculate the dot product between the vector and each channel location\n",
        "channel_locations = np.array([ch['loc'][:3] for ch in raw.info['chs']])\n",
        "dot_product = np.dot(channel_locations, ear_to_front_vector)\n",
        "\n",
        "# Select channels that have positive dot product values\n",
        "frontal_lobe_channels = [raw.ch_names[i] for i in np.where(dot_product > 0)[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(frontal_lobe_channels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(frontal_lobe_channels)\n",
        "print(\"Number of all lobe channels forward of midpoint: \", len(frontal_lobe_channels))\n",
        "# Select frontal lobe channels from MEG data\n",
        "raw_frontal_lobe = raw.copy().pick_channels(frontal_lobe_channels)\n",
        "raw_1 = raw_frontal_lobe.copy().pick_types('grad')\n",
        "print(\"Number of gradiometer channels selected forward of midpoint: \", len(raw_1.info['chs']))\n",
        "raw_1.compute_psd().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_resampled.compute_psd().plot_topomap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_1.compute_psd().plot_topomap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_1.save('Sub_1_ses_1_downsampled_channel_reduction-epo.epo', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "del sub_1_ses_1, epochs_resampled, epochs_baseline_corrected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_1_ses_2 = mne.io.read_raw_fif(\"D:\\charl\\Documents\\CE901_MEG_DATA_AND_CODE\\MEG_BIDS\\MEG_BIDS\\sub-1\\ses-2\\meg\\sub-1_ses-2_task-bcimici_meg.fif\", preload=True, allow_maxshield=True, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_2 = meg_preprocessing_pipeline(sub_1_ses_2)\n",
        "pipeline_2.apply_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_2 = mne.read_epochs(r\"D:\\charl\\Documents\\CE901_MEG_DATA_AND_CODE\\PROCESSING_PIPE\\SUB_1_SES_2\\epoched_sub_1_ses_2-epo.fif\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_2.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_2 = epochs_2.pick_types('grad')\n",
        "\n",
        "epochs_2.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_2.compute_psd().plot_topomap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_2.compute_psd(fmax=60).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_2_baseline_corrected = epochs_2.copy().apply_baseline((-0.2, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sfreq = 250\n",
        "epochs_2_resampled = epochs_2_baseline_corrected.copy().resample(new_sfreq, npad=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw = epochs_2_resampled\n",
        "\n",
        "# Get the coordinates of the fiducial points\n",
        "nasion = raw.info['dig'][0]['r']  # Nasion coordinate\n",
        "lpa = raw.info['dig'][1]['r']  # Left preauricular point coordinate\n",
        "rpa = raw.info['dig'][2]['r']  # Right preauricular point coordinate\n",
        "\n",
        "# Calculate the mid-point between the left and right preauricular points\n",
        "midpoint = (lpa + rpa)\n",
        "\n",
        "# Calculate the vector representing the direction from the ears forward\n",
        "ear_to_front_vector = nasion + midpoint\n",
        "\n",
        "# Calculate the dot product between the vector and each channel location\n",
        "channel_locations = np.array([ch['loc'][:3] for ch in raw.info['chs']])\n",
        "dot_product = np.dot(channel_locations, ear_to_front_vector)\n",
        "\n",
        "# Select channels that have positive dot product values\n",
        "frontal_lobe_channels = [raw.ch_names[i] for i in np.where(dot_product > 0)[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(frontal_lobe_channels)\n",
        "print(\"Number of all lobe channels forward of midpoint: \", len(frontal_lobe_channels))\n",
        "# Select frontal lobe channels from MEG data\n",
        "raw_frontal_lobe = raw.copy().pick_channels(frontal_lobe_channels)\n",
        "raw_2 = raw_frontal_lobe.copy().pick_types('grad')\n",
        "print(\"Number of gradiometer channels selected forward of midpoint: \", len(raw_1.info['chs']))\n",
        "raw_2.compute_psd().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_2.plot_psd_topomap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_2.save('sub_1_ses_2_downsampled_channel_reduced-epo.epo')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access the MEG channels and their 3D coordinates\n",
        "meg_channels = [ch for ch in epochs_decimated.info['chs'] if ch['kind'] == mne.io.constants.FIFF.FIFFV_MEG_CH]\n",
        "sensor_coordinates = [(ch['ch_name'], ch['loc'][:3]) for ch in meg_channels]\n",
        "\n",
        "# Print sensor names and their 3D coordinates\n",
        "for sensor_name, coord in sensor_coordinates:\n",
        "    print(sensor_name, coord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs.plot_sensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fiducials = [d for d in epochs.info['dig'] if d['kind'] == mne.io.constants.FIFF.FIFFV_POINT_CARDINAL]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frontal_sensors = []\n",
        "\n",
        "for sensor in sensor_locs:\n",
        "    x, y, z = sensor['loc'][:3]\n",
        "    if x > 0 and y > 0 and z > 0:\n",
        "        frontal_sensors.append(sensor['ch_name'])\n",
        "\n",
        "print(\"Frontal Lobe Sensors:\")\n",
        "for sensor in frontal_sensors:\n",
        "    print(sensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(frontal_sensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the sensor locations from the info attribute\n",
        "sensor_locs = epochs_decimated.info['chs']\n",
        "\n",
        "# Create a list to store the frontal lobe sensor names\n",
        "frontal_sensors = []\n",
        "\n",
        "# Loop over the sensor locations and check for frontal lobe coordinates\n",
        "for sensor in sensor_locs:\n",
        "    x, y, z = sensor['loc'][:3]  # Get x, y, z coordinates\n",
        "    if x > 0 and y > 0 and z > 0:\n",
        "        frontal_sensors.append(sensor['ch_name'])\n",
        "\n",
        "# Print the frontal lobe sensor names\n",
        "print(\"Frontal Lobe Sensors:\")\n",
        "for sensor in frontal_sensors:\n",
        "    print(sensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(frontal_sensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_channel_selection = epochs_decimated.copy().pick_channels(frontal_sensors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_channel_selection.plot(picks='grad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs_channel_selection.compute_psd().plot(picks='grad')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
